#!/usr/bin/env python

# Reads an OONI http_requests report and shows URLs that have known block pages.
#
# First, make an OONI report:
#   ooniprobe -i /usr/share/ooni/decks/complete_no_root.deck
# Then,
#   ./findblocks report-http_requests-XXXX.yamloo

# Should look for timeout blocks.
# http://www.freedomhouse.org: control_failure=task_timed_out

import csv
import datetime
import errno
import getopt
import os
import os.path
import re
import subprocess
import sys
import urllib
import urlparse
import yaml

from classify import classify_response

class options(object):
    save_blocks_dir = None

def usage(f=sys.stdout):
    f.write("""\
Usage: %s *-http_requests-v1-probe.yaml.gz

  --save-blocks=DIR  save block pages to directory DIR.
  -h, --help         show this help.
""" % sys.argv[0])

# Return a (nontor, tor) pair if there are exactly two requests and one is
# nontor and one is tor, or else raise an exception.
def split_requests(requests):
    nontor = None
    tor = None
    for request in requests:
        if request.get("failure") is not None:
            continue
        if not request["request"]["tor"]["is_tor"]:
            # It's possible for there to be more than one request of each type
            # (even with different User-Agents). I suppose it is a bug in
            # earlier ooniprobe that would reschedule both the Tor and non-Tor
            # retrieval if either of them failed. The first instance of this is
            # on 2013-05-02. It may be related to:
            # https://gitweb.torproject.org/ooni-probe.git/commit/?id=0bbd9a1e0c2f3f04120264fddabc3020692e4c01
            # https://gitweb.torproject.org/ooni-probe.git/commit/?id=3d2b9025ca372ca0fcdb88ce6e2cb050c1cf6e64
            if nontor is None:
                nontor = request
        else:
            if tor is None:
                tor = request
    return nontor, tor

def save_response(f, response):
    f.write("HTTP/1.0 %d xxx\r\n" % response["code"])
    for name, values in response["headers"]:
        for value in values:
            f.write("%s: %s\r\n" % (name, value))
    f.write("\r\n")
    f.write(response["body"])

def save_response_filename(filename, response):
    try:
        os.makedirs(os.path.dirname(filename))
    except OSError, e:
        if e.errno != errno.EEXIST:
            raise
    with open(filename, "w") as f:
        return save_response(f, response)

# Save a response with an automatically generated filename.
def save_response_filename_auto(header, request, response, class_):
    url = urlparse.urlsplit(request["url"])
    filename = "%s-%s-%s%s" % (header["report_id"], url.scheme, url.netloc, urlparse.urlunsplit((None, None, url.path, url.query, None)))
    filename = urllib.quote(filename, safe="")
    # Truncate name to filesystem limits.
    filename = filename[:255]
    filename = os.path.join(options.save_blocks_dir, class_, filename)
    return save_response_filename(filename, response)

# Canonicalize paths of "/" and "", which otherwise cause spurious URL
# differences.
def canonicalize_url(url):
    if type(url) == unicode:
        url = url.encode("utf-8")
    u = urlparse.urlsplit(url)
    if u.path == "/":
        u = (u.scheme, u.netloc, "", u.query, u.fragment)
    return urlparse.urlunsplit(u)

def boolf(v):
    if v:
        return "T"
    else:
        return "F"

def yaml_load_sloppy(f):
    # This is much faster than yaml.safe_load_all.
    y = yaml.load_all(f, Loader=yaml.CSafeLoader)
    while True:
        while True:
            try:
                doc = next(y)
                break
            except StopIteration:
                return
            except yaml.scanner.ScannerError, e:
                # Skip ahead to the next line.
                while True:
                    line = f.readline()
                    if not line or line == "...\n":
                        break
                print >> sys.stderr, "%s, skipping ahead" % e
                y = yaml.load_all(f, Loader=yaml.CSafeLoader)
        yield doc

# Fix some disparate entry formats so they are common enough to work with.
def fixup_entry(doc):
    assert doc["record_type"] == "entry"

    report = doc.get("report")
    if report is not None:
        # Some old OONI reports have some of the fields one level deeper under a
        # "report" key.
        for k, v in report.items():
            assert k not in doc
            doc[k] = v
        del doc["report"]

    # Some failures can lead to there being to requests array. For example,
    #   failure: Router $BD1907CD4E72F940F934FF932549599D886F9044 not in consensus.
    doc.setdefault("requests", [])

    for request in doc["requests"]:
        try:
            is_tor = request["request"]["tor"]
            # Some reports have tor:true and tor_false instead of having a
            # sub-table.
            if type(is_tor) == bool:
                request["request"]["tor"] = {"is_tor": is_tor}
        except KeyError:
            # Some older reports indicate the use of Tor by a special "shttp"
            # URL scheme.
            # https://gitweb.torproject.org/ooni-probe.git/tree/ooni/templates/httpt.py?id=7888084a8be52bdee4df69ac650b84ddb90e084e#n46
            # "To perform requests over Tor you will have to use the special URL
            # schema 'shttp'. For example to request / on example.com you will
            # have to do specify as URL 'shttp://example.com/'."
            if request["request"]["url"].startswith("shttp"):
                request["request"]["url"] = "http" + request["request"]["url"][5:]
                request["request"]["tor"] = {"is_tor": True}
            else:
                request["request"]["tor"] = {"is_tor": False}

    # Older reports don't summarize the individual request errors into toplevel
    # control_failure and experiment_failure members.
    # https://gitweb.torproject.org/ooni-probe.git/commit/?id=f8b13b0b9cb1fd453c77a887726318b04ffe148e
    doc.setdefault("control_failure", None)
    doc.setdefault("experiment_failure", None)
    for request in doc["requests"]:
        failure = request.get("failure")
        if failure is not None:
            if request["request"]["tor"]["is_tor"]:
                doc["control_failure"] = failure
            else:
                doc["experiment_failure"] = failure

    for request in doc["requests"]:
        try:
            response = request["response"]
        except KeyError:
            continue

        # YAMLOO can give us either a binary string (type str) or a Unicode string
        # (type unicode, with unspecified original encoding) for the body. If it's
        # Unicode, guess the encoding was UTF-8. It might be possible to scrape the
        # Content-Type for the encoding.
        body = response["body"]
        if body is None:
            response["body"] = ""
        elif type(body) == unicode:
            response["body"] = body.encode("utf-8")

        # And some web sites use non-ASCII in headers.
        for key, values in response["headers"]:
            for i in range(len(values)):
                if type(values[i]) == unicode:
                    values[i] = values[i].encode("utf-8")

    return doc

def process_file(f, filename):
    yamloo = yaml_load_sloppy(f)

    header = None
    for doc in yamloo:
        if doc["record_type"] == "header":
            assert header is None
            header = doc
            continue

        if doc["record_type"] != "entry":
            continue

        assert header is not None
        doc = fixup_entry(doc)

        if options.save_blocks_dir is not None:
            for request in doc["requests"]:
                try:
                    isblocked, class_ = classify_response(request["response"])
                except KeyError, e:
                    # No response.
                    continue
                if isblocked:
                    save_response_filename_auto(header, request["request"], request["response"], class_)

        nontor, tor = split_requests(doc["requests"])
        if nontor is None:
            print >> sys.stderr, "%s %s: missing is_tor:false request: %s" % (filename, doc["input"], doc["experiment_failure"])
        if tor is None:
            print >> sys.stderr, "%s %s: missing is_tor:true request: %s" % (filename, doc["input"], doc["control_failure"])
        if nontor is None or tor is None:
            continue

        nontor_isblocked, nontor_class = classify_response(nontor["response"])
        tor_isblocked, tor_class = classify_response(tor["response"])

        try:
            test_date = datetime.datetime.utcfromtimestamp(doc["test_start_time"])
        except KeyError:
            # Some reports don't have individual test_start_time.
            test_date = datetime.datetime.utcfromtimestamp(header["start_time"])
        csvw.writerow({
            "date": test_date.strftime("%Y-%m-%d %H:%M:%S"),
            "report_id": header["report_id"],
            "probe_cc": header["probe_cc"],
            "url": canonicalize_url(nontor["request"]["url"]),
            "nontor_isblocked": boolf(nontor_isblocked),
            "nontor_status": nontor["response"]["code"],
            "nontor_class": nontor_class,
            "tor_isblocked": boolf(tor_isblocked),
            "tor_status": tor["response"]["code"],
            # Sometimes exit_ip and exit_name are missing.
            "tor_exit_ip": tor["request"]["tor"].get("exit_ip", ""),
            "tor_exit_nickname": tor["request"]["tor"].get("exit_name", ""),
            "tor_class": tor_class,
        })
        sys.stdout.flush()

# Wow! Python's gzip module is slow! Uncompress with gzip instead. (Also has the
# advantage that decompression can use a separate core.)
def open_zcat(filename):
    p = subprocess.Popen(["gzip", "-dc", filename], stdout=subprocess.PIPE, bufsize=-1)
    return p.stdout

# Open a file optionally with gzip decompression based on the filename
# extension.
def magic_open(filename):
    if filename.endswith(".gz"):
        return open_zcat(filename)
    return open(filename)

def process_filename(filename):
    with magic_open(filename) as f:
        return process_file(f, filename)

if __name__ == "__main__":
    opts, args = getopt.gnu_getopt(sys.argv[1:], "h", ["save-blocks=", "help"])
    for o, a in opts:
        if o == "--save-blocks":
            options.save_blocks_dir = a
        elif o == "-h" or o == "--help":
            usage()
            sys.exit()

    csvw = csv.DictWriter(sys.stdout, fieldnames=["date", "report_id", "probe_cc", "nontor_isblocked", "nontor_status", "nontor_class", "tor_isblocked", "tor_status", "tor_class", "tor_exit_ip", "tor_exit_nickname", "url"], lineterminator="\n")
    csvw.writeheader()

    for filename in args:
        process_filename(filename)
