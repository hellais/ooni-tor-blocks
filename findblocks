#!/usr/bin/env python

# Reads an OONI http_requests report and shows URLs that have known block pages.
#
# First, make an OONI report:
#   ooniprobe -i /usr/share/ooni/decks/complete_no_root.deck
# Then,
#   ./findblocks report-http_requests-XXXX.yamloo

# Should look for timeout blocks.
# http://www.freedomhouse.org: control_failure=task_timed_out

import csv
import errno
import getopt
import gzip
import os
import os.path
import re
import sys
import urllib
import urlparse
import yaml

from bs4 import BeautifulSoup

class options(object):
    save_blocks_dir = None

def usage(f=sys.stdout):
    f.write("""\
Usage: %s *-http_requests-v1-probe.yaml.gz

  --save-blocks=DIR  save block pages to directory DIR.
  -h, --help         show this help.
""" % sys.argv[0])

# Get the first header value for the given key, or None if the header does not
# appear.
def get_header(response, fieldname):
    for name, values in response["headers"]:
        if name.lower() == fieldname.lower():
            return values[0]
    return None

# Return (is_block, description) tuple. 4?? and 5?? status codes are considered
# blocks. See the sample-blocks directory for the source files that led to these
# classifier rules.
def classify_response(response):
    status = response["code"]

    body = response["body"]
    if body is None:
        body = ""
    elif type(body) == unicode:
        body = body.encode("utf-8")

    if status == 403:
        if get_header(response, "Server") == "cloudflare-nginx" and re.search("<title>Attention Required! \\| CloudFlare</title>", body):
            return True, "403-CLOUDFLARE"
        if re.search("<meta http-equiv=\"Content-Type\" content=\"text/html; charset=windows-1256\"><title>M[0-9]-[0-9]\n", body):
            return True, "403-IRAN"
    if status == 404:
        if get_header(response, "Server") == "AkamaiGHost" and re.search("<H1>Access Denied</H1>\n \nYou don't have permission to access \"[^\"]*\" on this server\\.<P>\nReference&#32;&#35;", body):
            return True, "404-AKAMAI"

    if status // 100 == 4 or status // 100 == 5:
        return True, "%d-OTHER" % status
    return False, "%d" % status

# Return a (nontor, tor) pair if there are exactly two requests and one is
# nontor and one is tor, or else raise an exception.
def split_requests(requests):
    nontor = None
    tor = None
    for request in requests:
        if request.get("failure") is not None:
            continue
        if not request["request"]["tor"]["is_tor"]:
            if nontor is not None:
                raise ValueError("more than one is_tor:false request")
            nontor = request
        else:
            if tor is not None:
                raise ValueError("more than one is_tor:true request")
            tor = request
    if nontor is None:
        raise ValueError("missing is_tor:false request")
    if tor is None:
        raise ValueError("missing is_tor:true request")
    return nontor, tor

def save_response(f, response):
    f.write("HTTP/1.0 %d xxx\r\n" % response["code"])
    for name, values in response["headers"]:
        for value in values:
            f.write("%s: %s\r\n" % (name, value))
    f.write("\r\n")
    # YAMLOO can give us either a binary string (type str) or a Unicode string
    # (type unicode, with unspecified original encoding) for the body. If it's
    # Unicode, guess the encoding was UTF-8. It might be possible to scrape the
    # Content-Type for the encoding.
    body = response["body"]
    if body is None:
        body = ""
    elif type(body) == unicode:
        body = body.encode("utf-8")
    f.write(body)

def save_response_filename(filename, response):
    try:
        os.makedirs(os.path.dirname(filename))
    except OSError, e:
        if e.errno != errno.EEXIST:
            raise
    with open(filename, "w") as f:
        return save_response(f, response)

# Save a response with an automatically generated filename.
def save_response_filename_auto(header, request, response, class_):
    url = urlparse.urlsplit(request["url"])
    filename = "%s-%s-%s%s" % (header["report_id"], url.scheme, url.netloc, urlparse.urlunsplit((None, None, url.path, url.query, None)))
    filename = os.path.join(options.save_blocks_dir, class_, urllib.quote(filename, safe=""))
    return save_response_filename(filename, response)

def boolf(v):
    if v:
        return "T"
    else:
        return "F"

def process_file(f):
    yamloo = yaml.safe_load_all(f)

    header = None
    for doc in yamloo:
        if doc["record_type"] == "header":
            assert header is None
            header = doc
            continue

        if doc["record_type"] != "entry":
            continue

        assert header is not None

        if options.save_blocks_dir is not None:
            for request in doc["requests"]:
                try:
                    isblocked, class_ = classify_response(request["response"])
                except KeyError, e:
                    # No response.
                    continue
                if isblocked:
                    save_response_filename_auto(header, request["request"], request["response"], class_)

        try:
            nontor, tor = split_requests(doc["requests"])
        except ValueError, e:
            print >> sys.stderr, "%s: %s" % (doc["input"], str(e))
            continue

        nontor_isblocked, nontor_class = classify_response(nontor["response"])
        tor_isblocked, tor_class = classify_response(tor["response"])

        csvw.writerow({
            "report_id": header["report_id"],
            "probe_cc": header["probe_cc"],
            "url": doc["input"],
            "nontor_isblocked": boolf(nontor_isblocked),
            "nontor_status": nontor["response"]["code"],
            "nontor_class": nontor_class,
            "tor_isblocked": boolf(tor_isblocked),
            "tor_status": tor["response"]["code"],
            "tor_class": tor_class,
        })
        sys.stdout.flush()

# Open a file optionally with gzip decompression based on the filename
# extension.
def magic_open(filename):
    if filename.endswith(".gz"):
        return gzip.GzipFile(filename)
    return open(filename)

def process_filename(filename):
    with magic_open(filename) as f:
        return process_file(f)

opts, args = getopt.gnu_getopt(sys.argv[1:], "h", ["save-blocks=", "help"])
for o, a in opts:
    if o == "--save-blocks":
        options.save_blocks_dir = a
    elif o == "-h" or o == "--help":
        usage()
        sys.exit()

csvw = csv.DictWriter(sys.stdout, fieldnames=["report_id", "probe_cc", "nontor_isblocked", "nontor_status", "nontor_class", "tor_isblocked", "tor_status", "tor_class", "url"], lineterminator="\n")
csvw.writeheader()

for filename in args:
    process_filename(filename)
